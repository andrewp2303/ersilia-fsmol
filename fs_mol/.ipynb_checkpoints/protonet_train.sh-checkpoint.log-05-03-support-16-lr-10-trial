2024-05-05 09:53:09: Starting train run FSMol_ProtoNet_gnn+ecfp+fc_2024-05-05_09-53-09.
2024-05-05 09:53:09: 	Arguments: Namespace(DATA_PATH='/home/gridsan/ppaschalidis/Ersilia-FS/dataset/min_size_16', task_list_file='/home/gridsan/ppaschalidis/Ersilia-FS/dataset/min_size_16/entire_train_set.json', save_dir='/home/gridsan/ppaschalidis/Ersilia-FS/fs_mol/outputs/train/FSMol_ProtoNet_2024-05-03-support-16', seed=0, azureml_logging=False, features='gnn+ecfp+fc', distance_metric='mahalanobis', gnn_type='PNA', node_embed_dim=128, num_heads=4, per_head_dim=64, intermediate_dim=1024, message_function_depth=1, num_gnn_layers=10, readout_type='combined', readout_use_all_states=True, readout_num_heads=12, readout_head_dim=64, readout_output_dim=512, support_set_size=16, query_set_size=256, tasks_per_batch=16, batch_size=256, num_train_steps=2500, validate_every=100, validation_support_set_sizes=[16], validation_query_set_size=512, validation_num_samples=5, lr=10.0, clip_value=None, pretrained_gnn='/home/gridsan/ppaschalidis/Ersilia-FS/weights/multitask_best_model.pt', pretrained_pn=None)
2024-05-05 09:53:09: 	Output dir: /home/gridsan/ppaschalidis/Ersilia-FS/fs_mol/outputs/train/FSMol_ProtoNet_2024-05-03-support-16/FSMol_ProtoNet_gnn+ecfp+fc_2024-05-05_09-53-09
2024-05-05 09:53:09: 	Data path: /home/gridsan/ppaschalidis/Ersilia-FS/dataset/min_size_16
2024-05-05 09:53:09: Identified 655 training tasks.
2024-05-05 09:53:09: Identified 34 validation tasks.
2024-05-05 09:53:09: Identified 200 test tasks.
2024-05-05 09:53:09: 	Device: cpu
2024-05-05 09:53:09: 	Num parameters 19042338
2024-05-05 09:53:09: 	Model:
PrototypicalNetworkTrainer(
  (graph_feature_extractor): GraphFeatureExtractor(
    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)
    (gnn): GNN(
      (gnn_blocks): ModuleList(
        (0): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (1): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (2): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (3): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (4): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (5): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (6): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (7): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (8): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
        (9): GNNBlock(
          (mp_layers): ModuleList(
            (0): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (1): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (2): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
            (3): RelationalMultiAggrMP(
              (message_fns): ModuleList(
                (0): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (1): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
                (2): MLP(
                  (_layers): Sequential(
                    (0): Linear(in_features=64, out_features=192, bias=True)
                  )
                )
              )
            )
          )
          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)
          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (boom_layer): BOOMLayer(
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (activation): LeakyReLU(negative_slope=0.01)
            (dropout): Dropout(p=0.0, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
          )
          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout_layer): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (readout): CombinedGraphReadout(
      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(
        (_scoring_module): MLP(
          (_layers): Sequential(
            (0): Linear(in_features=1408, out_features=768, bias=True)
            (1): ReLU()
            (2): Linear(in_features=768, out_features=12, bias=True)
          )
        )
        (_transformation_mlp): MLP(
          (_layers): Sequential(
            (0): Linear(in_features=1408, out_features=768, bias=True)
            (1): ReLU()
            (2): Linear(in_features=768, out_features=768, bias=True)
          )
        )
        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)
      )
      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(
        (_scoring_module): MLP(
          (_layers): Sequential(
            (0): Linear(in_features=1408, out_features=768, bias=True)
            (1): ReLU()
            (2): Linear(in_features=768, out_features=12, bias=True)
          )
        )
        (_transformation_mlp): MLP(
          (_layers): Sequential(
            (0): Linear(in_features=1408, out_features=768, bias=True)
            (1): ReLU()
            (2): Linear(in_features=768, out_features=768, bias=True)
          )
        )
        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)
      )
      (_max_pooler): UnweightedGraphReadout(
        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)
      )
      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)
    )
  )
  (fc): Sequential(
    (0): Linear(in_features=2560, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=512, bias=True)
  )
)
2024-05-05 09:53:09: Loading pretrained GNN weights from /home/gridsan/ppaschalidis/Ersilia-FS/weights/multitask_best_model.pt.
Our state dict keys:  odict_keys(['graph_feature_extractor.init_node_proj.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.alpha', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.alpha', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.alpha', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.alpha', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.alpha', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.alpha', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.alpha', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.alpha', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.alpha', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.alpha', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_norm_layer.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._scoring_module._layers.0.weight', 'graph_feature_extractor.readout._weighted_mean_pooler._scoring_module._layers.0.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._scoring_module._layers.2.weight', 'graph_feature_extractor.readout._weighted_mean_pooler._scoring_module._layers.2.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._transformation_mlp._layers.0.weight', 'graph_feature_extractor.readout._weighted_mean_pooler._transformation_mlp._layers.0.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._transformation_mlp._layers.2.weight', 'graph_feature_extractor.readout._weighted_mean_pooler._transformation_mlp._layers.2.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._combination_layer.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._scoring_module._layers.0.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._scoring_module._layers.0.bias', 'graph_feature_extractor.readout._weighted_sum_pooler._scoring_module._layers.2.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._scoring_module._layers.2.bias', 'graph_feature_extractor.readout._weighted_sum_pooler._transformation_mlp._layers.0.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._transformation_mlp._layers.0.bias', 'graph_feature_extractor.readout._weighted_sum_pooler._transformation_mlp._layers.2.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._transformation_mlp._layers.2.bias', 'graph_feature_extractor.readout._weighted_sum_pooler._combination_layer.weight', 'graph_feature_extractor.readout._max_pooler._combination_layer.weight', 'graph_feature_extractor.readout._combination_layer.weight', 'fc.0.weight', 'fc.0.bias', 'fc.2.weight', 'fc.2.bias'])
GNN state dict keys:  odict_keys(['graph_feature_extractor.init_node_proj.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.alpha', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.0.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.alpha', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.1.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.alpha', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.2.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.alpha', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.3.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.alpha', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.4.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.alpha', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.5.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.alpha', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.6.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.alpha', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.7.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.alpha', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.8.boom_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.alpha', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.0.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.1.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.2.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.0._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.0._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.1._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.1._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.2._layers.0.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_layers.3.message_fns.2._layers.0.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.msg_out_projection.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.msg_out_projection.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.mp_norm_layer.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_layer.linear1.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_layer.linear1.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_layer.linear2.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_layer.linear2.bias', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_norm_layer.weight', 'graph_feature_extractor.gnn.gnn_blocks.9.boom_norm_layer.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._scoring_module._layers.0.weight', 'graph_feature_extractor.readout._weighted_mean_pooler._scoring_module._layers.0.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._scoring_module._layers.2.weight', 'graph_feature_extractor.readout._weighted_mean_pooler._scoring_module._layers.2.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._transformation_mlp._layers.0.weight', 'graph_feature_extractor.readout._weighted_mean_pooler._transformation_mlp._layers.0.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._transformation_mlp._layers.2.weight', 'graph_feature_extractor.readout._weighted_mean_pooler._transformation_mlp._layers.2.bias', 'graph_feature_extractor.readout._weighted_mean_pooler._combination_layer.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._scoring_module._layers.0.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._scoring_module._layers.0.bias', 'graph_feature_extractor.readout._weighted_sum_pooler._scoring_module._layers.2.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._scoring_module._layers.2.bias', 'graph_feature_extractor.readout._weighted_sum_pooler._transformation_mlp._layers.0.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._transformation_mlp._layers.0.bias', 'graph_feature_extractor.readout._weighted_sum_pooler._transformation_mlp._layers.2.weight', 'graph_feature_extractor.readout._weighted_sum_pooler._transformation_mlp._layers.2.bias', 'graph_feature_extractor.readout._weighted_sum_pooler._combination_layer.weight', 'graph_feature_extractor.readout._max_pooler._combination_layer.weight', 'graph_feature_extractor.readout._combination_layer.weight', 'tail_mlp._layers.0.weight', 'tail_mlp._layers.0.bias', 'tail_mlp._layers.2.weight', 'tail_mlp._layers.2.bias'])
2024-05-05 09:53:10: CHEMBL3285745:
2024-05-05 09:53:10: CHEMBL761987:
2024-05-05 09:53:10: CHEMBL1794398:
2024-05-05 09:53:10: CHEMBL1259550:
2024-05-05 09:53:10: CHEMBL703466:
2024-05-05 09:53:10: CHEMBL3761618:
2024-05-05 09:53:10: CHEMBL3227331:
2024-05-05 09:53:10: CHEMBL3383460:
2024-05-05 09:53:10: CHEMBL695986:
2024-05-05 09:53:10: CHEMBL995355:
2024-05-05 09:53:10: CHEMBL4197926:
2024-05-05 09:53:10: CHEMBL833990:
2024-05-05 09:53:10: CHEMBL1047854:
2024-05-05 09:53:10: CHEMBL2162371:
2024-05-05 09:53:10: CHEMBL863382:
2024-05-05 09:53:10: CHEMBL3625422:
2024-05-05 09:53:10: CHEMBL4002825:
2024-05-05 09:53:10: CHEMBL2150628:
2024-05-05 09:53:10: CHEMBL1177528:
2024-05-05 09:53:10: CHEMBL3588714:
2024-05-05 09:53:10: CHEMBL895182:
2024-05-05 09:53:10: CHEMBL1020690:
2024-05-05 09:53:10: CHEMBL1107214:
2024-05-05 09:53:10: CHEMBL4187321:
2024-05-05 09:53:10: CHEMBL930744:
2024-05-05 09:53:10: CHEMBL804251:
2024-05-05 09:53:10: CHEMBL1068293:
2024-05-05 09:53:10: CHEMBL909968:
2024-05-05 09:53:10: CHEMBL1107997:
2024-05-05 09:53:10: CHEMBL1053167:
2024-05-05 09:53:10: CHEMBL1055019:
2024-05-05 09:53:10: CHEMBL2328533:
2024-05-05 09:53:10: CHEMBL871033:
2024-05-05 09:53:10: CHEMBL1941610:
2024-05-05 09:53:10: CHEMBL956777:
2024-05-05 09:53:10: CHEMBL3389542:
2024-05-05 09:53:10: CHEMBL4432407:
2024-05-05 09:53:10: CHEMBL1767670:
2024-05-05 09:53:10: CHEMBL2388705:
2024-05-05 09:53:10: CHEMBL656397:
2024-05-05 09:53:10: CHEMBL4263092:
2024-05-05 09:53:10: CHEMBL3384578:
2024-05-05 09:53:10: CHEMBL1034018:
2024-05-05 09:53:10: CHEMBL3405593:
2024-05-05 09:53:10: CHEMBL3295662:
2024-05-05 09:53:10: CHEMBL1803360:
2024-05-05 09:53:10: CHEMBL833931:
2024-05-05 09:53:10: CHEMBL2447603:
2024-05-05 09:53:10: CHEMBL4054609:
2024-05-05 09:53:10: CHEMBL710534:
2024-05-05 09:53:10: CHEMBL1116600:
2024-05-05 09:53:10: CHEMBL2051603:
2024-05-05 09:53:10: CHEMBL860970:
2024-05-05 09:53:10: CHEMBL1816524:
2024-05-05 09:53:10: CHEMBL3266569:
2024-05-05 09:53:10: CHEMBL922474:
2024-05-05 09:53:10: CHEMBL941164:
2024-05-05 09:53:10: CHEMBL1121169:
2024-05-05 09:53:10: CHEMBL713255:
2024-05-05 09:53:10: CHEMBL2024927:
2024-05-05 09:53:10: CHEMBL1960697:
2024-05-05 09:53:10: CHEMBL3367829:
2024-05-05 09:53:10: CHEMBL937510:
2024-05-05 09:53:10: CHEMBL2405783:
2024-05-05 09:53:10: CHEMBL1051810:
2024-05-05 09:53:10: CHEMBL3396060:
2024-05-05 09:53:10: CHEMBL708445:
2024-05-05 09:53:10: CHEMBL2051598:
2024-05-05 09:53:10: CHEMBL4136409:
2024-05-05 09:53:10: CHEMBL4194391:
2024-05-05 09:53:10: CHEMBL1763053:
2024-05-05 09:53:10: CHEMBL2067378:
2024-05-05 09:53:10: CHEMBL826375:
2024-05-05 09:53:10: CHEMBL889770:
2024-05-05 09:53:10: CHEMBL903139:
2024-05-05 09:53:10: CHEMBL2033222:
2024-05-05 09:53:10: CHEMBL3240111:
2024-05-05 09:53:10: CHEMBL712878:
2024-05-05 09:53:10: CHEMBL713409:
2024-05-05 09:53:10: CHEMBL1815005:
2024-05-05 09:53:10: CHEMBL3295663:
2024-05-05 09:53:10: CHEMBL2148600:
2024-05-05 09:53:10: CHEMBL1228542:
2024-05-05 09:53:10: CHEMBL1018957:
2024-05-05 09:53:10: CHEMBL2072118:
2024-05-05 09:53:10: CHEMBL1654782:
2024-05-05 09:53:10: CHEMBL1260089:
2024-05-05 09:53:10: CHEMBL4719106:
2024-05-05 09:53:10: CHEMBL2019245:
2024-05-05 09:53:10: CHEMBL3067105:
2024-05-05 09:53:10: CHEMBL1654780:
2024-05-05 09:53:10: CHEMBL961554:
2024-05-05 09:53:10: CHEMBL2341227:
2024-05-05 09:53:10: CHEMBL2154555:
2024-05-05 09:53:10: CHEMBL899618:
2024-05-05 09:53:10: CHEMBL1219015:
2024-05-05 09:53:10: CHEMBL902229:
2024-05-05 09:53:10: CHEMBL833275:
2024-05-05 09:53:10: CHEMBL3413997:
2024-05-05 09:53:10: CHEMBL2445761:
2024-05-05 09:53:10: CHEMBL3578893:
2024-05-05 09:53:10: CHEMBL3418331:
2024-05-05 09:53:10: CHEMBL833792:
2024-05-05 09:53:10: CHEMBL1053306:
2024-05-05 09:53:10: CHEMBL1017067:
2024-05-05 09:53:10: CHEMBL1033996:
2024-05-05 09:53:10: CHEMBL889768:
2024-05-05 09:53:10: CHEMBL2405555:
2024-05-05 09:53:10: CHEMBL1052565:
2024-05-05 09:53:10: CHEMBL3390310:
2024-05-05 09:53:10: CHEMBL1932094:
2024-05-05 09:53:10: CHEMBL2379584:
2024-05-05 09:53:10: CHEMBL689145:
2024-05-05 09:53:10: CHEMBL984423:
2024-05-05 09:53:10: CHEMBL2210037:
2024-05-05 09:53:10: CHEMBL1930242:
2024-05-05 09:53:10: CHEMBL4253251:
2024-05-05 09:53:10: CHEMBL833117:
2024-05-05 09:53:10: CHEMBL1817498:
2024-05-05 09:53:10: CHEMBL1837558:
2024-05-05 09:53:10: CHEMBL1039164:
2024-05-05 09:53:10: CHEMBL3073615:
2024-05-05 09:53:10: CHEMBL908714:
2024-05-05 09:53:10: CHEMBL906490:
2024-05-05 09:53:10: CHEMBL899467:
2024-05-05 09:53:10: CHEMBL995360:
2024-05-05 09:53:10: CHEMBL1953907:
2024-05-05 09:53:10: CHEMBL1056891:
2024-05-05 09:53:10: CHEMBL833080:
2024-05-05 09:53:10: CHEMBL1794318:
2024-05-05 09:53:10: CHEMBL3122259:
2024-05-05 09:53:10: CHEMBL936680:
2024-05-05 09:53:10: CHEMBL1024879:
2024-05-05 09:53:11: CHEMBL2342597:
2024-05-05 09:53:11: CHEMBL3282588:
2024-05-05 09:53:12: CHEMBL3078730:
2024-05-05 09:53:13: CHEMBL860972:
2024-05-05 09:53:13: CHEMBL3295321:
2024-05-05 09:53:14: CHEMBL3815782:
2024-05-05 09:53:14: CHEMBL3088595:
2024-05-05 09:53:15: CHEMBL655136:
2024-05-05 09:53:16: CHEMBL3418917:
2024-05-05 09:53:17: CHEMBL924692:
2024-05-05 09:53:18: CHEMBL713254:
2024-05-05 09:53:19: CHEMBL1024326:
2024-05-05 09:53:19: CHEMBL1059735:
2024-05-05 09:53:21: CHEMBL683837:
2024-05-05 09:53:22: CHEMBL1816523:
2024-05-05 09:53:22: CHEMBL3129213:
2024-05-05 09:53:23: CHEMBL3077285:
2024-05-05 09:53:25: CHEMBL4477287:
2024-05-05 09:53:25: CHEMBL2390255:
2024-05-05 09:53:26: CHEMBL711656:
2024-05-05 09:53:27: CHEMBL3295320:
2024-05-05 09:53:27: CHEMBL758925:
2024-05-05 09:53:29: CHEMBL1035506:
2024-05-05 09:53:30: CHEMBL1054762:
2024-05-05 09:53:30: CHEMBL906554:
2024-05-05 09:53:31: CHEMBL1921081:
2024-05-05 09:53:32: CHEMBL3072372:
2024-05-05 09:53:32: CHEMBL698789:
2024-05-05 09:53:33: CHEMBL1109063:
2024-05-05 09:53:34: CHEMBL1073156:
2024-05-05 09:53:34: CHEMBL972376:
2024-05-05 09:53:34: CHEMBL2432161:
2024-05-05 09:53:36: CHEMBL1035508:
2024-05-05 09:53:36: CHEMBL2167912:
2024-05-05 09:53:37: CHEMBL3418701:
2024-05-05 09:53:38: CHEMBL1034017:
2024-05-05 09:53:38: CHEMBL2317095:
2024-05-05 09:53:39: CHEMBL1067060:
2024-05-05 09:53:40: CHEMBL2156781:
2024-05-05 09:53:40: CHEMBL1037279:
2024-05-05 09:53:40: CHEMBL711804:
2024-05-05 09:53:41: CHEMBL4006616:
2024-05-05 09:53:42: CHEMBL944781:
2024-05-05 09:53:43: CHEMBL833378:
2024-05-05 09:53:43: CHEMBL1663615:
2024-05-05 09:53:44: CHEMBL3295870:
2024-05-05 09:53:45: CHEMBL2183320:
2024-05-05 09:53:46: CHEMBL3122349:
2024-05-05 09:53:47: CHEMBL873604:
2024-05-05 09:53:49: CHEMBL1817497:
2024-05-05 09:53:50: CHEMBL944749:
2024-05-05 09:53:51: CHEMBL4220813:
2024-05-05 09:53:52: CHEMBL4002824:
2024-05-05 09:53:53: CHEMBL3592342:
2024-05-05 09:53:54: CHEMBL3129215:
2024-05-05 09:53:54: CHEMBL1918205:
2024-05-05 09:53:55: CHEMBL1006568:
2024-05-05 09:53:56: CHEMBL1918204:
2024-05-05 09:53:57: CHEMBL3123043:
2024-05-05 09:53:58: CHEMBL4179593:
2024-05-05 09:53:59: CHEMBL1045728:
2024-05-05 09:54:00: CHEMBL837535:
2024-05-05 09:54:00: CHEMBL4184680:
2024-05-05 09:54:02: CHEMBL955134:
2024-05-05 09:54:03: CHEMBL1769611:
2024-05-05 09:54:08: CHEMBL4050758:
2024-05-05 09:54:09: CHEMBL3994798:
2024-05-05 09:54:09: CHEMBL706945:
2024-05-05 09:54:10: CHEMBL2390645:
2024-05-05 09:54:11: CHEMBL907807:
2024-05-05 09:54:12: CHEMBL956847:
2024-05-05 09:54:12: CHEMBL1043900:
2024-05-05 09:54:13: CHEMBL946064:
2024-05-05 09:54:14: CHEMBL4264727:
